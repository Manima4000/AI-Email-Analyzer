# Classificador de E-mails com IA üìß‚ú®

![Badge de Status](https://img.shields.io/badge/status-funcional-brightgreen)
![Badge do Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Badge do FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![Badge do Docker](https://img.shields.io/badge/Docker-conteinerizado-blue)


> Um classificador de e-mails inteligente que utiliza a API do Google Gemini para categorizar mensagens e sugerir respostas autom√°ticas, tudo atrav√©s de uma interface web limpa e moderna. O projeto √© totalmente containerizado com Docker, garantindo uma execu√ß√£o f√°cil e consistente em qualquer ambiente.


---

## üìö Tabela de Conte√∫dos

* [Sobre o Projeto](#-sobre-o-projeto)
* [Tecnologias Utilizadas](#-tecnologias-utilizadas)
* [Principais Features](#-principais-features)
* [Como Rodar o Projeto Localmente](#-como-rodar-o-projeto-localmente)
  * [Pr√©-requisitos](#pr√©-requisitos)
  * [Instru√ß√µes (Docker)](#instru√ß√µes-docker)
* [Rodando os Testes](#-rodando-os-testes)
* [Configura√ß√£o Avan√ßada](#-configura√ß√£o-avan√ßada)
  * [Escolhendo o Modelo de IA](#escolhendo-o-modelo-de-ia)
  * [Rodando Manualmente (Sem Docker)](#rodando-manualmente-sem-docker)
* [Estrat√©gia de Deploy](#-estrat√©gia-de-deploy)
* [Pr√≥ximos Passos](#-pr√≥ximos-passos)
* [Contato](#-contato)

---

## üéØ Sobre o Projeto

Este projeto simula uma ferramenta de automa√ß√£o e produtividade. A aplica√ß√£o permite que um usu√°rio cole o texto de um e-mail ou fa√ßa o upload de um arquivo (`.txt`/`.pdf`) e, em segundos, receba uma an√°lise gerada por IA sobre o conte√∫do, al√©m de uma sugest√£o de resposta.

O objetivo era construir uma aplica√ß√£o full-stack completa, demonstrando boas pr√°ticas de desenvolvimento, como:
* **Containeriza√ß√£o:** Uso de Docker e Docker Compose para garantir portabilidade e facilidade de execu√ß√£o.
* **Arquitetura Desacoplada:** Frontend e backend como servi√ßos independentes.
* **Qualidade de C√≥digo:** Cobertura de testes automatizados com Pytest.
* **Configura√ß√£o Flex√≠vel:** Uso de vari√°veis de ambiente (`.env`) para gerenciar chaves e configura√ß√µes.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Backend:** Python, FastAPI, Uvicorn
* **Intelig√™ncia Artificial:** Google Gemini Pro API
* **Frontend:** HTML5, CSS3, JavaScript (Vanilla JS), NGINX
* **Testes:** Pytest, pytest-asyncio
* **Containeriza√ß√£o:** Docker, Docker Compose
* **Deploy:** Vercel (Frontend), Render (Backend)

---

## ‚ú® Principais Features

* **An√°lise por IA:** Sugest√£o de respostas via Google Gemini.
* **M√∫ltiplos Formatos de Entrada:** Suporte para texto colado e upload de arquivos `.txt` e `.pdf`.
* **Interface Reativa:** Feedback visual de "carregando" durante o processamento.
* **Tema Claro e Escuro (Dark Mode):** Com persist√™ncia da escolha do usu√°rio.
* **Modelo de IA Configur√°vel:** Permite a troca f√°cil do modelo Gemini via vari√°veis de ambiente.
* **Execu√ß√£o Simplificada:** O projeto inteiro (frontend e backend) sobe com um √∫nico comando `docker-compose up`.
* **Cobertura de Testes:** Testes de unidade e integra√ß√£o para garantir a robustez da API.

---

## üöÄ Como Rodar o Projeto Localmente

Siga as instru√ß√µes abaixo para ter o projeto rodando na sua m√°quina em segundos.

### Pr√©-requisitos
* [Git](https://git-scm.com/)
* [Docker](https://www.docker.com/products/docker-desktop/) e [Docker Compose](https://docs.docker.com/compose/install/)

### Instru√ß√µes (Docker)

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Configure suas vari√°veis de ambiente:**
    * Na pasta `backend`, crie uma c√≥pia do arquivo `.env.example` e renomeie-a para `.env`.
    * Abra o arquivo `.env` e preencha as vari√°veis:
        ```env
        GOOGLE_API_KEY="SUA_CHAVE_API_AQUI"

        MODEL_NAME="gemini-pro" #Pode escolher o modelo de sua prefer√™ncia
        ```

3.  **Suba os containers com Docker Compose:**
    * Na **pasta raiz do projeto**, execute:
    ```bash
    docker-compose up --build
    ```
    * O Docker ir√° construir a imagem do backend, baixar a do frontend e iniciar os dois servi√ßos.

4.  **Acesse a aplica√ß√£o:**
    * **Frontend:** Abra seu navegador e acesse **`http://localhost:5500`**.
    * **Backend API Docs:** A documenta√ß√£o interativa da API estar√° dispon√≠vel em **`http://localhost:8000/docs`**.

---

## ‚úÖ Rodando os Testes

Para garantir que a l√≥gica do backend est√° funcionando corretamente, voc√™ pode rodar a su√≠te de testes automatizados.

1.  **Siga os passos de configura√ß√£o do "M√©todo Manual"** (veja na se√ß√£o de Configura√ß√£o Avan√ßada) para criar e ativar o ambiente virtual (`.venv`) e instalar as depend√™ncias (`pip install -r requirements.txt`).

2.  **Execute o Pytest:**
    * Na pasta `backend`, execute o comando apropriado para o seu sistema operacional:

    * **No Windows (PowerShell):**
        ```powershell
        $env:PYTHONPATH="."; pytest -v
        ```

    * **No Windows (CMD):**
        ```powershell
        set PYTHONPATH=.
        pytest -v
        ```

    * **No macOS/Linux:**
        ```bash
        PYTHONPATH=. pytest -v
        ```

---

## ‚öôÔ∏è Configura√ß√£o Avan√ßada

### Escolhendo o Modelo de IA
A disponibilidade dos modelos do Gemini pode variar. Inclu√≠mos um script para voc√™ verificar quais modelos sua chave de API pode acessar.

1.  Configure o ambiente do backend manualmente (veja o pr√≥ximo passo).
2.  Na pasta `backend`, execute o script de verifica√ß√£o:
    ```bash
    python check_models.py
    ```
3.  O terminal listar√° os modelos dispon√≠veis. Copie o nome de um deles e cole como o valor da vari√°vel `MODEL_NAME` no seu arquivo `.env`.

### Rodando Manualmente (Sem Docker)

1.  **Configure o Backend:**
    ```bash
    cd backend
    python -m venv .venv
    # Windows: .\.venv\Scripts\activate | macOS/Linux: source .venv/bin/activate

    # O arquivo requirements.txt lista todas as bibliotecas Python que o projeto precisa.
    pip install -r requirements.txt

    # Crie e configure o arquivo .env (como no m√©todo Docker)
    uvicorn app.main:app --reload
    ```
    * O backend estar√° rodando em `http://localhost:8000`.

2.  **Rode o Frontend:**
    * Use uma extens√£o como o **"Live Server"** no VS Code ou inicie um servidor Python na pasta `frontend`:
    ```bash
    cd frontend
    python -m http.server 5500
    ```
    * Acesse `http://localhost:5500`.

---

## ‚òÅÔ∏è Estrat√©gia de Deploy

* **Frontend (Vercel):** O conte√∫do da pasta `frontend` pode ser implantado como um "Static Site" na Vercel.
* **Backend (Render):** O backend na pasta `backend` √© containerizado e pode ser implantado como um "Web Service" na plataforma Render.

---

## üß≠ Pr√≥ximos Passos
* [ ] Hist√≥rico de an√°lises salvo no navegador.
* [ ] Op√ß√£o de ajustar o "tom" da resposta sugerida (Formal, Amig√°vel, etc.).
* [ ] CI/CD com GitHub Actions para rodar os testes automaticamente.

---

## üë§ Contato

**[Seu Nome]**

* **LinkedIn:** `[Link para o seu LinkedIn]`
* **GitHub:** `[Link para o seu GitHub]`
* **E-mail:** `[Seu E-mail]`
